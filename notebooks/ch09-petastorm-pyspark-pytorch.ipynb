{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7c6a5a",
   "metadata": {},
   "source": [
    "# Tutorial in chapter 09 - petastorm-pyspark-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12256f40",
   "metadata": {},
   "source": [
    "### 1. load parquet data into pytorch loader\n",
    "\n",
    "file path: `notebooks/images_data/silver/augmented`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1fc3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import BinaryType,StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions \n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#petastorm\n",
    "\n",
    "from petastorm.spark import SparkDatasetConverter, make_spark_converter\n",
    "from petastorm import TransformSpec \n",
    "    \n",
    "    \n",
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from functools import partial \n",
    "\n",
    "\n",
    "# train images with pytorch\n",
    "#from torchvision import transforms\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# import mlflow\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97770b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark session:\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Distributed Pytorch training\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",True) \\\n",
    "    .config(\"spark.memory.offHeap.size\",\"30g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7a667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm.spark import SparkDatasetConverter, make_spark_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a16abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, 'petastorm_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcacae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"images_data/silver/augmented\"\n",
    "mlflow_model_dir_path = \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35adda1",
   "metadata": {},
   "source": [
    "# Enable MLFlow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47880879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "try:\n",
    "    from torchmetrics.functional import accuracy\n",
    "except ImportError:\n",
    "    from pytorch_lightning.metrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4088b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/29 17:03:49 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "2022/05/29 17:03:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/conda/lib/python3.9/site-packages/pytorch_lightning/core/memory.py:16: LightningDeprecationWarning: `pytorch_lightning.core.memory.get_memory_profile` and `pytorch_lightning.core.memory.get_gpu_memory_map` have been moved to `pytorch_lightning.utilities.memory` since v1.5 and will be removed in v1.7.\"\n",
      "2022/05/29 17:03:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/conda/lib/python3.9/site-packages/pytorch_lightning/core/memory.py:25: LightningDeprecationWarning: `pytorch_lightning.core.memory.LayerSummary` and `pytorch_lightning.core.memory.ModelSummary` have been moved to `pytorch_lightning.utilities.model_summary` since v1.5 and will be removed in v1.7.\"\n"
     ]
    }
   ],
   "source": [
    "#Enable MLFlow tracking\n",
    "mlflow.set_experiment(mlflow_model_dir_path)\n",
    "# requires pytorch_lightning\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad2fab",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa07f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 5\n",
    "#The number of **epochs** is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset. One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters.\n",
    "SAMPLE_SIZE = 50\n",
    "NUM_EPOCHS = 1\n",
    "NUM_EXECUTERS = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccbca2",
   "metadata": {},
   "source": [
    "## 2. Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b06782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data stored in parquet, limiting the dataset for the example\n",
    "df_parquet = spark.read.parquet(data_path)\n",
    "df = df_parquet.select(col(\"content\"), col(\"label_index\").cast(LongType())).limit(SAMPLE_SIZE)\n",
    "  \n",
    "num_classes = df.select(\"label_index\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b2b101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes =4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3121989",
   "metadata": {},
   "source": [
    "## 3. Split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2360759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train , df_val = df.randomSplit([0.6,0.4], seed=12345)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ef9d0",
   "metadata": {},
   "source": [
    "## 4. Cache the Spark DataFrame using Petastorm Spark Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030d22ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
      "  self._filesystem = pyarrow.localfs\n"
     ]
    }
   ],
   "source": [
    "tmp_path = \"file:/home/jovyan/petastorm_cache/\"\n",
    "\n",
    "# Set a cache directory on DBFS FUSE for intermediate data\n",
    "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF,tmp_path)\n",
    "\n",
    "# TIP: Use a low value for parquet_row_group_bytes. The detafault of 32 MiB can be too high for larger datasets. Using 1MB instead.\n",
    "#train\n",
    "converter_train = make_spark_converter(df_train, parquet_row_group_size_bytes=32000000)\n",
    "#test\n",
    "converter_val = make_spark_converter(df_val, parquet_row_group_size_bytes=32000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0df1a",
   "metadata": {},
   "source": [
    "### Petastorm prepreocess\n",
    "used during materlizing spark dataframe with petastorm and bridging to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41a8dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision, torch\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "def preprocess(grayscale_image):\n",
    "  \"\"\"\n",
    "  Preprocess an image file bytes for MobileNetV2 (ImageNet).\n",
    "  \"\"\"\n",
    "  image = Image.open(io.BytesIO(grayscale_image)).resize([224, 224])\n",
    "  image_array = np.array(image) \n",
    "\n",
    "  #image_array = keras.preprocessing.image.img_to_array(image)\n",
    "  return image_array\n",
    "\n",
    "def transform_row(pd_batch):\n",
    "  \"\"\"\n",
    "  The input and output of this function are pandas dataframes.\n",
    "  \"\"\"\n",
    "  pd_batch['features'] = pd_batch['content'].map(lambda x: preprocess(x))\n",
    "  pd_batch = pd_batch.drop(labels=['content'], axis=1)\n",
    "  return pd_batch\n",
    "\n",
    "# The output shape of the `TransformSpec` is not automatically known by petastorm, \n",
    "# so you need to specify the shape for new columns in `edit_fields` and specify the order of \n",
    "# the output columns in `selected_fields`.\n",
    "transform_spec_fn = TransformSpec(\n",
    "  func=transform_row, \n",
    "  edit_fields=[('features', np.uint8 , IMG_SHAPE, False)], \n",
    "  selected_fields=['features', 'label_index']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ea1c3",
   "metadata": {},
   "source": [
    "## 5. Get the model MobileNetV2\n",
    "#### Get the model MobileNetV2 from torch hub\n",
    "and only retraint it's final layer to fit our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c16f5f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /home/jovyan/.cache/torch/hub/v0.10.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95679333bcdf453d8501d2a63b102a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86897160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):  # pylint: disable=arguments-differ\n",
    "        x = x.view((-1, 1, 28, 28))\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45782ed",
   "metadata": {},
   "source": [
    "## 6. set the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41b15688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, steps=100, lr=0.0005, momentum=0.5):\n",
    "    model = Net()\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    loss_hist = []\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        if batch_idx > steps:\n",
    "            break\n",
    "        data, target = Variable(batch['features']), Variable(batch['label_index'])\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            logging.info('[%d/%d]\\tLoss: %.6f', batch_idx, steps, loss.data.item())\n",
    "            loss_hist.append(loss.data.item())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d98235f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_len = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            data, target = batch['features'], batch['label']\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            test_len += data.shape[0]\n",
    "\n",
    "    test_loss /= test_len\n",
    "    accuracy = correct / test_len\n",
    "\n",
    "    logging.info('Test set: Average loss: %.4f, Accuracy: %d/%d (%.0f%%)',\n",
    "                 test_loss, correct, test_len, 100. * accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "077544e2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def train_and_evaluate(_=None):\n",
    "    with converter_train.make_torch_dataloader(transform_spec=transform_spec_fn) as loader:\n",
    "            model = train(loader)\n",
    "    \n",
    "    with converter_test.make_torch_dataloader(transform_spec=transform_spec_fn,num_epochs=1) as loader:\n",
    "            accuracy = test(model, loader)\n",
    "            return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ceeb7a80",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Byte but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-64d4463f474e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-f49aa44d361d>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mconverter_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_torch_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_spec_fn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m            \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mconverter_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_torch_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_spec_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-b0f7f23167c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, steps, lr, momentum)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-95cd71b138ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=arguments-differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 443\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Byte but found Float"
     ]
    }
   ],
   "source": [
    " accuracy = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b843f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
